# ğŸš€ Smart Log Compressor & Router

Um sistema de ingestÃ£o de logs de alta performance desenvolvido para otimizar a escrita em bancos de dados e reduzir custos de infraestrutura atravÃ©s de compressÃ£o em memÃ³ria e persistÃªncia em lote (batching).

## ğŸ’¡ O Problema
Sistemas de missÃ£o crÃ­tica podem gerar milhares de logs idÃªnticos em poucos segundos durante uma falha. Salvar cada um desses logs individualmente causa:
1. **Gargalo de I/O:** O banco de dados trava tentando processar tantas escritas.
2. **Custo Elevado:** Armazenamento de dados redundantes.
3. **RuÃ­do:** Dificuldade para encontrar a causa raiz no meio de milhares de mensagens iguais.

## âœ¨ A SoluÃ§Ã£o
Este projeto atua como um **buffer inteligente**. Ele utiliza **Redis** para agrupar logs idÃªnticos em tempo real e persiste apenas um resumo estatÃ­stico no **MongoDB Atlas (Nuvem)** a cada ciclo de tempo.

### Diferenciais TÃ©cnicos:
- **DeduplicaÃ§Ã£o via Hash (MD5):** Identifica mensagens idÃªnticas instantaneamente atravÃ©s do conteÃºdo da mensagem.
- **Armazenamento em MemÃ³ria (Redis):** LatÃªncia ultra-baixa na recepÃ§Ã£o dos dados.
- **PersistÃªncia HÃ­brida:** Utiliza Redis local para velocidade e MongoDB Atlas para armazenamento persistente e escalÃ¡vel.
- **Garantia de Tipagem:** ValidaÃ§Ã£o de schemas com **Zod**.



## ğŸ§ª Garantia de Qualidade (Testes)
O projeto conta com uma suÃ­te de testes unitÃ¡rios utilizando **Jest** para garantir que a lÃ³gica de compressÃ£o nunca falhe. Os testes validam:
- Se logs idÃªnticos geram o mesmo hash e incrementam o contador corretamente.
- Se logs diferentes geram hashes distintos, evitando colisÃµes de dados.

Para rodar os testes:
```bash
npm test

---
Desenvolvido por **Victor Miguel** - www.linkedin.com/in/victor-miguel-2847ba267